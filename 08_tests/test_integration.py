"""
–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ç–µ—Å—Ç—ã –¥–ª—è Feature Engineering Pipeline.

–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –ø–æ–ª–Ω—ã–π workflow –∏ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—é –º–µ–∂–¥—É –º–æ–¥—É–ª—è–º–∏.
"""

import sys
import pytest
import pandas as pd
import numpy as np
from pathlib import Path
import tempfile
import yaml
from unittest.mock import patch, Mock

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –º–æ–¥—É–ª—è–º
project_root = Path(__file__).parent.parent
sys.path.append(str(project_root / '03_src'))

from features import FeatureEngineeringPipeline


class TestFullPipeline:
    """–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ç–µ—Å—Ç—ã –ø–æ–ª–Ω–æ–≥–æ –ø–∞–π–ø–ª–∞–π–Ω–∞."""
    
    def create_test_csv(self, n_periods=200):
        """–°–æ–∑–¥–∞–µ—Ç –≤—Ä–µ–º–µ–Ω–Ω—ã–π CSV —Ñ–∞–π–ª —Å —Ç–µ—Å—Ç–æ–≤—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏."""
        np.random.seed(42)
        
        dates = pd.date_range('2020-01-01', periods=n_periods, freq='h')
        
        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã—Ö FOREX –¥–∞–Ω–Ω—ã—Ö
        returns = np.random.normal(0, 0.001, n_periods)
        prices = [1.1000]  # –ù–∞—á–∞–ª—å–Ω–∞—è —Ü–µ–Ω–∞ EUR/USD
        
        for ret in returns[1:]:
            new_price = prices[-1] * (1 + ret)
            prices.append(max(new_price, 0.5))  # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —Ü–µ–Ω–∞
        
        # –°–æ–∑–¥–∞–Ω–∏–µ OHLC
        data = []
        for i, (date, close_price) in enumerate(zip(dates, prices)):
            if i == 0:
                open_price = close_price
            else:
                open_price = prices[i-1] * (1 + np.random.normal(0, 0.0002))
            
            # High –∏ Low –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ Open –∏ Close
            high_base = max(open_price, close_price)
            low_base = min(open_price, close_price)
            
            high = high_base * (1 + abs(np.random.normal(0, 0.001)))
            low = low_base * (1 - abs(np.random.normal(0, 0.001)))
            
            volume = np.random.randint(1000, 15000)
            
            data.append({
                'time': date.strftime('%Y-%m-%d %H:%M:%S+00:00'),
                'open': round(open_price, 5),
                'high': round(high, 5),
                'low': round(low, 5),
                'close': round(close_price, 5),
                'volume': volume
            })
        
        df = pd.DataFrame(data)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤–æ –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
        temp_file = tempfile.NamedTemporaryFile(mode='w', suffix='.csv', delete=False)
        df.to_csv(temp_file.name, index=False)
        temp_file.close()
        
        return temp_file.name
    
    def create_test_config(self, profile="quick"):
        """–°–æ–∑–¥–∞–µ—Ç –≤—Ä–µ–º–µ–Ω–Ω—É—é –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –¥–ª—è —Ç–µ—Å—Ç–æ–≤."""
        if profile == "quick":
            config = {
                'technical_indicators': {
                    'ema_periods': [10, 21],
                    'macd_params': {'fast': 12, 'slow': 26, 'signal': 9},
                    'rsi_period': 14,
                    'bb_params': {'period': 20, 'std_dev': 2.0}
                },
                'statistical_features': {
                    'roc_periods': [1, 5],
                    'rolling_windows': [10, 20],
                    'zscore_windows': [20]
                },
                'lag_features': {
                    'price_columns': ['Close'],
                    'price_lags': [1, 5, 24],
                    'volume_lags': [1, 5],
                    'return_periods': [1],
                    'return_lags': [1],
                    'seasonal_periods': []  # –£–±–∏—Ä–∞–µ–º –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ —Ç–µ—Å—Ç–∞
                },
                'pipeline_settings': {
                    'missing_values': {'strategy': 'drop', 'min_periods_required': 50},
                    'validation': {'check_duplicates': True, 'check_sorting': True},
                    'demo_size': 100,
                    'parquet_settings': {
                        'engine': 'pyarrow',
                        'compression': 'snappy',
                        'index': True
                    }
                }
            }
        else:
            # –ü–æ–ª–Ω–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–ª—è —Ç–µ—Å—Ç–æ–≤ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
            config = {
                'technical_indicators': {
                    'ema_periods': [9, 12, 21, 50, 200],
                    'macd_params': {'fast': 12, 'slow': 26, 'signal': 9},
                    'rsi_period': 14,
                    'stoch_params': {'k_period': 14, 'd_period': 3},
                    'cci_period': 20,
                    'atr_period': 14,
                    'bb_params': {'period': 20, 'std_dev': 2.0},
                    'adx_period': 14,
                    'momentum_period': 10,
                    'cmf_period': 20
                },
                'statistical_features': {
                    'roc_periods': [1, 5, 10, 20],
                    'rolling_windows': [5, 10, 20, 50],
                    'zscore_windows': [5, 10, 20],
                    'skew_kurt_windows': [10, 20],
                    'volatility_windows': [10, 20],
                    'trend_windows': [10, 20]
                },
                'lag_features': {
                    'price_columns': ['Close', 'Open'],
                    'price_lags': [1, 2, 5, 10, 24],
                    'volume_lags': [1, 2, 5, 10],
                    'return_periods': [1, 5, 10],
                    'return_lags': [1, 2, 5],
                    'seasonal_periods': [24]
                },
                'pipeline_settings': {
                    'missing_values': {'strategy': 'drop', 'min_periods_required': 200},
                    'validation': {'check_duplicates': True, 'check_sorting': True}
                }
            }
        
        temp_file = tempfile.NamedTemporaryFile(mode='w', suffix='.yml', delete=False)
        yaml.dump(config, temp_file, default_flow_style=False)
        temp_file.close()
        
        return temp_file.name
    
    def test_full_pipeline_quick(self):
        """–¢–µ—Å—Ç –ø–æ–ª–Ω–æ–≥–æ –ø–∞–π–ø–ª–∞–π–Ω–∞ —Å –±—ã—Å—Ç—Ä–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π."""
        csv_file = self.create_test_csv(100)
        config_file = self.create_test_config("quick")
        
        try:
            with tempfile.TemporaryDirectory() as temp_dir:
                output_file = Path(temp_dir) / "test_features.parquet"
                
                # –ú–æ–∫–∞–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –ø—É—Ç–µ–π –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
                with patch.object(FeatureEngineeringPipeline, '_load_config') as mock_config:
                    # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ä–µ–∞–ª—å–Ω—É—é –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –∏ –æ–±–Ω–æ–≤–ª—è–µ–º –ø—É—Ç–∏
                    with open(config_file, 'r') as f:
                        config = yaml.safe_load(f)
                    
                    config['pipeline_settings']['input_file'] = csv_file
                    config['pipeline_settings']['output_file'] = str(output_file)
                    config['pipeline_settings']['output_demo_file'] = str(output_file.with_suffix('.demo.parquet'))
                    
                    mock_config.return_value = config
                    
                    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∏ –∑–∞–ø—É—Å–∫–∞–µ–º –ø–∞–π–ø–ª–∞–π–Ω
                    pipeline = FeatureEngineeringPipeline()
                    df_result, stats = pipeline.run_full_pipeline()
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
                    assert isinstance(df_result, pd.DataFrame)
                    assert len(df_result) > 0
                    assert len(df_result.columns) > 5  # –ë–æ–ª—å—à–µ —á–µ–º –∏—Å—Ö–æ–¥–Ω—ã–µ OHLCV
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
                    assert stats['created_features'] > 0
                    assert stats['total_columns'] == len(df_result.columns)
                    assert stats['processing_time'] > 0
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö
                    assert df_result.index.is_monotonic_increasing  # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ –≤—Ä–µ–º–µ–Ω–∏
                    assert df_result.isnull().sum().sum() == 0  # –ù–µ—Ç –ø—Ä–æ–ø—É—Å–∫–æ–≤ –ø–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏
                    
                    print(f"‚úÖ –ë—ã—Å—Ç—Ä—ã–π —Ç–µ—Å—Ç –ø—Ä–æ–π–¥–µ–Ω:")
                    print(f"   –°–æ–∑–¥–∞–Ω–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {stats['created_features']}")
                    print(f"   –ò—Ç–æ–≥–æ –∫–æ–ª–æ–Ω–æ–∫: {stats['total_columns']}")
                    print(f"   –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {stats['processing_time']:.2f} —Å–µ–∫")
        
        finally:
            Path(csv_file).unlink()
            Path(config_file).unlink()
    
    def test_pipeline_with_different_profiles(self):
        """–¢–µ—Å—Ç –ø–∞–π–ø–ª–∞–π–Ω–∞ —Å —Ä–∞–∑–Ω—ã–º–∏ –ø—Ä–æ—Ñ–∏–ª—è–º–∏."""
        csv_file = self.create_test_csv(80)
        
        try:
            # –¢–µ—Å—Ç —Å –ø—Ä–æ—Ñ–∏–ª–µ–º "quick"
            with patch('pathlib.Path.exists', return_value=False):
                pipeline_quick = FeatureEngineeringPipeline(profile="quick")
                
                # –ú–æ–∫–∞–µ–º –∑–∞–≥—Ä—É–∑–∫—É –¥–∞–Ω–Ω—ã—Ö
                test_df = pd.read_csv(csv_file)
                test_df['time'] = pd.to_datetime(test_df['time'])
                test_df = test_df.set_index('time')
                test_df.columns = ['Open', 'High', 'Low', 'Close', 'Volume']
                
                result_quick = pipeline_quick.create_features(test_df.copy())
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ quick –ø—Ä–æ—Ñ–∏–ª—å —Å–æ–∑–¥–∞–µ—Ç –º–µ–Ω—å—à–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
                assert len(result_quick.columns) > len(test_df.columns)
                assert len(result_quick.columns) < 100  # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –¥–ª—è quick
                
            print(f"‚úÖ Quick –ø—Ä–æ—Ñ–∏–ª—å: {len(result_quick.columns)} –∫–æ–ª–æ–Ω–æ–∫")
        
        finally:
            Path(csv_file).unlink()
    
    def test_pipeline_error_handling(self):
        """–¢–µ—Å—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—à–∏–±–æ–∫ –≤ –ø–∞–π–ø–ª–∞–π–Ω–µ."""
        # –¢–µ—Å—Ç —Å –Ω–µ—Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º —Ñ–∞–π–ª–æ–º
        pipeline = FeatureEngineeringPipeline()
        
        with pytest.raises(FileNotFoundError):
            pipeline.load_data("–Ω–µ—Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π_—Ñ–∞–π–ª.csv")
        
        # –¢–µ—Å—Ç —Å –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
        with tempfile.NamedTemporaryFile(mode='w', suffix='.csv', delete=False) as temp_file:
            # –°–æ–∑–¥–∞–µ–º —Ñ–∞–π–ª —Å –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä–æ–π
            temp_file.write("col1,col2\n1,2\n3,4\n")
            temp_file.close()
            
            try:
                df_invalid = pipeline.load_data(temp_file.name)
                # –î–æ–ª–∂–µ–Ω –∑–∞–≥—Ä—É–∑–∏—Ç—å—Å—è, –Ω–æ —Å –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è–º–∏
                assert len(df_invalid) > 0
                
            finally:
                Path(temp_file.name).unlink()
    
    def test_pipeline_memory_usage(self):
        """–¢–µ—Å—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ø–∞–º—è—Ç–∏ –ø–∞–π–ø–ª–∞–π–Ω–æ–º."""
        csv_file = self.create_test_csv(500)  # –ë–æ–ª—å—à–∏–π –¥–∞—Ç–∞—Å–µ—Ç
        config_file = self.create_test_config("quick")
        
        try:
            with patch.object(FeatureEngineeringPipeline, '_load_config') as mock_config:
                with open(config_file, 'r') as f:
                    config = yaml.safe_load(f)
                config['pipeline_settings']['input_file'] = csv_file
                mock_config.return_value = config
                
                pipeline = FeatureEngineeringPipeline()
                
                # –ò–∑–º–µ—Ä—è–µ–º –ø–∞–º—è—Ç—å –¥–æ
                import psutil
                process = psutil.Process()
                memory_before = process.memory_info().rss / 1024 / 1024  # MB
                
                df_result, stats = pipeline.run_full_pipeline()
                
                # –ò–∑–º–µ—Ä—è–µ–º –ø–∞–º—è—Ç—å –ø–æ—Å–ª–µ
                memory_after = process.memory_info().rss / 1024 / 1024  # MB
                memory_used = memory_after - memory_before
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑—É–º–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏
                data_size_mb = df_result.memory_usage(deep=True).sum() / 1024 / 1024
                
                print(f"üìä –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏:")
                print(f"   –†–∞–∑–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö: {data_size_mb:.2f} MB")
                print(f"   –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ –ø–∞–º—è—Ç–∏: {memory_used:.2f} MB")
                print(f"   –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å: {data_size_mb/memory_used:.2f}")
                
                # –ü–∞–º—è—Ç—å –Ω–µ –¥–æ–ª–∂–Ω–∞ –ø—Ä–µ–≤—ã—à–∞—Ç—å —Ä–∞–∑—É–º–Ω—ã–µ –ø—Ä–µ–¥–µ–ª—ã
                assert memory_used < 500, f"–°–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏: {memory_used:.2f} MB"
        
        finally:
            Path(csv_file).unlink()
            Path(config_file).unlink()
    
    def test_pipeline_performance(self):
        """–¢–µ—Å—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –ø–∞–π–ø–ª–∞–π–Ω–∞."""
        csv_file = self.create_test_csv(1000)  # –ë–æ–ª—å—à–æ–π –¥–∞—Ç–∞—Å–µ—Ç
        config_file = self.create_test_config("full")
        
        try:
            import time
            
            with patch.object(FeatureEngineeringPipeline, '_load_config') as mock_config:
                with open(config_file, 'r') as f:
                    config = yaml.safe_load(f)
                config['pipeline_settings']['input_file'] = csv_file
                mock_config.return_value = config
                
                pipeline = FeatureEngineeringPipeline()
                
                start_time = time.time()
                df_result, stats = pipeline.run_full_pipeline()
                end_time = time.time()
                
                execution_time = end_time - start_time
                records_per_second = len(df_result) / execution_time
                features_per_second = len(df_result.columns) * len(df_result) / execution_time
                
                print(f"‚ö° –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å:")
                print(f"   –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {execution_time:.2f} —Å–µ–∫")
                print(f"   –ó–∞–ø–∏—Å–µ–π –≤ —Å–µ–∫—É–Ω–¥—É: {records_per_second:.0f}")
                print(f"   –ü—Ä–∏–∑–Ω–∞–∫–æ–≤ –≤ —Å–µ–∫—É–Ω–¥—É: {features_per_second:.0f}")
                print(f"   –°–æ–∑–¥–∞–Ω–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {stats['created_features']}")
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑—É–º–Ω—É—é –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
                assert execution_time < 120, f"–°–ª–∏—à–∫–æ–º –º–µ–¥–ª–µ–Ω–Ω–æ–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ: {execution_time:.2f} —Å–µ–∫"
                assert records_per_second > 10, f"–°–ª–∏—à–∫–æ–º –Ω–∏–∑–∫–∞—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {records_per_second:.2f} –∑–∞–ø–∏—Å–µ–π/—Å–µ–∫"
        
        finally:
            Path(csv_file).unlink()
            Path(config_file).unlink()
    
    def test_pipeline_data_consistency(self):
        """–¢–µ—Å—Ç –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏ –¥–∞–Ω–Ω—ã—Ö —á–µ—Ä–µ–∑ –ø–∞–π–ø–ª–∞–π–Ω."""
        csv_file = self.create_test_csv(200)
        config_file = self.create_test_config("quick")
        
        try:
            with patch.object(FeatureEngineeringPipeline, '_load_config') as mock_config:
                with open(config_file, 'r') as f:
                    config = yaml.safe_load(f)
                config['pipeline_settings']['input_file'] = csv_file
                mock_config.return_value = config
                
                pipeline = FeatureEngineeringPipeline()
                
                # –ó–∞–ø—É—Å–∫–∞–µ–º –ø–∞–π–ø–ª–∞–π–Ω –¥–≤–∞–∂–¥—ã
                df_result1, stats1 = pipeline.run_full_pipeline()
                
                # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π –ø–∞–π–ø–ª–∞–π–Ω —Å —Ç–æ–π –∂–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π
                pipeline2 = FeatureEngineeringPipeline()
                pipeline2.config = config
                df_result2, stats2 = pipeline2.run_full_pipeline()
                
                # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –∏–¥–µ–Ω—Ç–∏—á–Ω—ã–º–∏
                assert len(df_result1) == len(df_result2)
                assert len(df_result1.columns) == len(df_result2.columns)
                assert list(df_result1.columns) == list(df_result2.columns)
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á–∏—Å–ª–æ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è (—Å –¥–æ–ø—É—Å–∫–æ–º –Ω–∞ –ø–æ–≥—Ä–µ—à–Ω–æ—Å—Ç–∏ –≤—ã—á–∏—Å–ª–µ–Ω–∏–π)
                numeric_cols = df_result1.select_dtypes(include=[np.number]).columns
                for col in numeric_cols:
                    if not df_result1[col].equals(df_result2[col]):
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å –Ω–µ–±–æ–ª—å—à–∏–º –¥–æ–ø—É—Å–∫–æ–º
                        diff = (df_result1[col] - df_result2[col]).abs()
                        max_diff = diff.max()
                        assert max_diff < 1e-10, f"–ë–æ–ª—å—à–∞—è —Ä–∞–∑–Ω–∏—Ü–∞ –≤ –∫–æ–ª–æ–Ω–∫–µ {col}: {max_diff}"
                
                print(f"‚úÖ –¢–µ—Å—Ç –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏ –ø—Ä–æ–π–¥–µ–Ω")
                print(f"   –ö–æ–ª–æ–Ω–æ–∫: {len(df_result1.columns)}")
                print(f"   –ó–∞–ø–∏—Å–µ–π: {len(df_result1)}")
        
        finally:
            Path(csv_file).unlink()
            Path(config_file).unlink()


class TestRealWorldScenarios:
    """–¢–µ—Å—Ç—ã —Ä–µ–∞–ª—å–Ω—ã—Ö —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è."""
    
    def test_missing_data_scenarios(self):
        """–¢–µ—Å—Ç —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤ —Å –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏."""
        # –°–æ–∑–¥–∞–µ–º –¥–∞–Ω–Ω—ã–µ —Å —Ä–∞–∑–ª–∏—á–Ω—ã–º–∏ —Ç–∏–ø–∞–º–∏ –ø—Ä–æ–ø—É—Å–∫–æ–≤
        dates = pd.date_range('2020-01-01', periods=100, freq='h')
        df = pd.DataFrame({
            'Open': np.random.uniform(1.0, 1.2, 100),
            'High': np.random.uniform(1.1, 1.3, 100),
            'Low': np.random.uniform(0.9, 1.1, 100),
            'Close': np.random.uniform(1.0, 1.2, 100),
            'Volume': np.random.randint(1000, 5000, 100)
        }, index=dates)
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Ä–∞–∑–Ω—ã–µ —Ç–∏–ø—ã –ø—Ä–æ–ø—É—Å–∫–æ–≤
        df.iloc[10:15, 1] = np.nan  # –ü—Ä–æ–ø—É—Å–∫–∏ –≤ —Å–µ—Ä–µ–¥–∏–Ω–µ (High)
        df.iloc[0:5, 4] = np.nan    # –ü—Ä–æ–ø—É—Å–∫–∏ –≤ –Ω–∞—á–∞–ª–µ (Volume)
        df.iloc[-5:, 3] = np.nan    # –ü—Ä–æ–ø—É—Å–∫–∏ –≤ –∫–æ–Ω—Ü–µ (Close)
        
        pipeline = FeatureEngineeringPipeline()
        
        # –¢–µ—Å—Ç —Å drop —Å—Ç—Ä–∞—Ç–µ–≥–∏–µ–π
        pipeline.config = {
            'pipeline_settings': {'missing_values': {'strategy': 'drop'}},
            'technical_indicators': {'ema_periods': [10]},
            'statistical_features': {'roc_periods': [1]},
            'lag_features': {'price_columns': ['Close'], 'price_lags': [1]}
        }
        
        result = pipeline.create_features(df)
        
        # –ü–æ—Å–ª–µ drop –Ω–µ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –ø—Ä–æ–ø—É—Å–∫–æ–≤
        assert result.isnull().sum().sum() == 0
        assert len(result) < len(df)  # –ß–∞—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å —É–¥–∞–ª–µ–Ω–∞
        
        print(f"‚úÖ –¢–µ—Å—Ç –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö: {len(df)} -> {len(result)} –∑–∞–ø–∏—Å–µ–π")
    
    def test_extreme_values(self):
        """–¢–µ—Å—Ç —Å —ç–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏."""
        dates = pd.date_range('2020-01-01', periods=50, freq='h')
        
        # –°–æ–∑–¥–∞–µ–º –¥–∞–Ω–Ω—ã–µ —Å —ç–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏
        df = pd.DataFrame({
            'Open': [1.0] * 50,
            'High': [1.1] * 50,
            'Low': [0.9] * 50,
            'Close': [1.0] * 50,
            'Volume': [1000] * 50
        }, index=dates)
        
        # –î–æ–±–∞–≤–ª—è–µ–º —ç–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
        df.iloc[25, df.columns.get_loc('Close')] = 100.0  # –û—á–µ–Ω—å –≤—ã—Å–æ–∫–∞—è —Ü–µ–Ω–∞
        df.iloc[26, df.columns.get_loc('Close')] = 0.01   # –û—á–µ–Ω—å –Ω–∏–∑–∫–∞—è —Ü–µ–Ω–∞
        df.iloc[27, df.columns.get_loc('Volume')] = 1000000  # –û—á–µ–Ω—å –±–æ–ª—å—à–æ–π –æ–±—ä–µ–º
        
        pipeline = FeatureEngineeringPipeline()
        result = pipeline.create_features(df)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –ø–∞–π–ø–ª–∞–π–Ω —Å–ø—Ä–∞–≤–∏–ª—Å—è —Å —ç–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏
        assert len(result) > 0
        assert not result.isin([np.inf, -np.inf]).any().any()  # –ù–µ—Ç –±–µ—Å–∫–æ–Ω–µ—á–Ω–æ—Å—Ç–µ–π
        
        print(f"‚úÖ –¢–µ—Å—Ç —ç–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π –ø—Ä–æ–π–¥–µ–Ω")


if __name__ == "__main__":
    # –ó–∞–ø—É—Å–∫ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω–Ω—ã—Ö —Ç–µ—Å—Ç–æ–≤
    pytest.main([__file__, "-v", "--tb=short", "-s"])